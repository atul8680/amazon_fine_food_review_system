{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_csv(\"Reviews.csv\")\n",
    "sorted_data = dataset.sort_values('ProductId')\n",
    "data = sorted_data.drop_duplicates(subset={'UserId','ProfileName','Time','Text'})\n",
    "data[data['HelpfulnessNumerator'] > data['HelpfulnessDenominator']]\n",
    "data = data[data['HelpfulnessNumerator'] <= data['HelpfulnessDenominator']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['Score'] != 3]\n",
    "data['Score'] = data['Score'].replace([1,2],0)\n",
    "data['Score'] = data['Score'].replace([4,5],1)\n",
    "data = data.sort_values(by=['Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Text=data['Text']\n",
    "stop = set(stopwords.words('english'))\n",
    "sno= nltk.stem.SnowballStemmer('english')\n",
    "stop.remove('not')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove unneccessary symbols\n",
    "postive_word = []\n",
    "negative_word = []\n",
    "final_text = []\n",
    "j=0\n",
    "s=''\n",
    "for i in Text.values:\n",
    "    sent = []\n",
    "    i = re.sub(r'[^a-zA-Z]',' ',i)\n",
    "    for words in i.split():\n",
    "        if(len(words)>2) and words not in stop:\n",
    "            #s=(sno.stem(words.lower()))\n",
    "            s=words.lower()\n",
    "            sent.append(s);\n",
    "            if data['Score'].values[j] == 1:\n",
    "                postive_word.append(s)\n",
    "            if data['Score'].values[j] == 0:\n",
    "                negative_word.append(s)\n",
    "    final_text.append(sent)\n",
    "    j += 1\n",
    "            \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "364159"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(final_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "glov_file = 'glove.6B.100d.txt'\n",
    "op_file = 'glove.6B.100d.txt.word2vec'\n",
    "glove2word2vec(glov_file,op_file)\n",
    "model = KeyedVectors.load_word2vec_format(op_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# avg w2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  import sys\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in true_divide\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "364159\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "avg_text_vec = []\n",
    "for sen in final_text:\n",
    "    sen_vec = np.zeros(100)\n",
    "    count=0\n",
    "    for word in sen:\n",
    "        try:\n",
    "            vec = model.wv[word]\n",
    "            sen_vec += vec;\n",
    "            count += 1\n",
    "        except:\n",
    "            pass\n",
    "    sen_vec /= count\n",
    "    avg_text_vec.append(sen_vec)\n",
    "\n",
    "print(len(avg_text_vec))\n",
    "print(len(avg_text_vec[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_text_vec_np = pd.DataFrame(avg_text_vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_data = data['Score'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    307052\n",
       "0     57107\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192734\n",
      "227581\n",
      "356684\n"
     ]
    }
   ],
   "source": [
    "for i,k in enumerate(avg_text_vec_np[0].isnull()):\n",
    "    if(k):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_text_vec_np=avg_text_vec_np.dropna(axis=0)\n",
    "op_data=np.delete(op_data,[192734,227581,356684])\n",
    "avg_text_vec_np = avg_text_vec_np.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_in = avg_text_vec_np[:290000,:]\n",
    "test_in = avg_text_vec_np[290000:,:]\n",
    "train_op = op_data[:290000]\n",
    "test_op = op_data[290000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# applying models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  0.8700696055684456\n",
      "2  0.856628674265147\n",
      "3  0.8945290468133108\n",
      "4  0.8897772701313535\n",
      "5  0.8939478067740144\n",
      "6  0.8935933147632311\n",
      "7  0.893687707641196\n",
      "8  0.8929561841375485\n",
      "9  0.893687707641196\n",
      "10  0.8945615982241953\n",
      "11  0.8941828254847646\n",
      "12  0.893569844789357\n",
      "13  0.8947951273532669\n",
      "14  0.8941828254847646\n",
      "15  0.8941828254847646\n",
      "16  0.8941828254847646\n",
      "17  0.8947951273532669\n",
      "18  0.8947951273532669\n",
      "19  0.8947951273532669\n"
     ]
    }
   ],
   "source": [
    "for k in range(1,20):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    model = knn.fit(train_in[:1000,:],train_op[:1000])\n",
    "    pred = model.predict(test_in[:1000,:])\n",
    "    acc = f1_score(test_op[:1000],pred)\n",
    "    print(str(k) + \"  \"+ str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "model = knn.fit(train_in,train_op)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test_in[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = f1_score(test_op[:10000],pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9165434906196702\n"
     ]
    }
   ],
   "source": [
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = GaussianNB()\n",
    "model_nb = nb.fit(train_in,train_op)\n",
    "pred_nb = model_nb.predict(test_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8187759205730804\n"
     ]
    }
   ],
   "source": [
    "acc_nb = f1_score(test_op,pred_nb)\n",
    "print(acc_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logistic regerssion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = LogisticRegression().fit(train_in,train_op)\n",
    "pred_lr = model_lr.predict(test_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9251522860410297\n"
     ]
    }
   ],
   "source": [
    "acc_lr = f1_score(test_op,pred_lr)\n",
    "print(acc_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_svm = SVC().fit(train_in[:10000,:],train_op[:10000])\n",
    "pred_svm = model_svm.predict(test_in[:10000,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.905488972801401\n"
     ]
    }
   ],
   "source": [
    "acc_svm= f1_score(test_op[:10000],pred_svm)\n",
    "print(acc_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dt = DecisionTreeClassifier(random_state=0).fit(train_in,train_op)\n",
    "pred_dt = model_dt.predict(test_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8647169348909403\n"
     ]
    }
   ],
   "source": [
    "acc_dt= f1_score(test_op,pred_dt)\n",
    "print(acc_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf = RandomForestClassifier(random_state=0).fit(train_in,train_op)\n",
    "pred_rf = model_rf.predict(test_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9094091225896384\n"
     ]
    }
   ],
   "source": [
    "acc_rf= f1_score(test_op,pred_rf)\n",
    "print(acc_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# boosting classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gb = GradientBoostingClassifier(random_state=0).fit(train_in,train_op)\n",
    "pred_gb = model_gb.predict(test_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_gb= f1_score(test_op,pred_gb)\n",
    "print(acc_gb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ab =AdaBoostClassifier(random_state=0).fit(train_in,train_op)\n",
    "pred_ab = model_ab.predict(test_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_ab= f1_score(test_op,pred_ab)\n",
    "print(acc_ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
